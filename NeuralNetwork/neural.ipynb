{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./digit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "           ..\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Name: 1, Length: 784, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18,  30, 137,\n",
       "        137, 192,  86,  72,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  13,  86, 250, 254, 254,\n",
       "        254, 254, 217, 246, 151,  32,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  16, 179, 254, 254, 254, 254,\n",
       "        254, 254, 254, 254, 254, 231,  54,  15,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  72, 254, 254, 254, 254, 254,\n",
       "        254, 254, 254, 254, 254, 254, 254, 104,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  61, 191, 254, 254, 254, 254, 254,\n",
       "        109,  83, 199, 254, 254, 254, 254, 243,  85,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 172, 254, 254, 254, 202, 147, 147,\n",
       "         45,   0,  11,  29, 200, 254, 254, 254, 171,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1, 174, 254, 254,  89,  67,   0,   0,\n",
       "          0,   0,   0,   0, 128, 252, 254, 254, 212,  76,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  47, 254, 254, 254,  29,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  83, 254, 254, 254, 153,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  80, 254, 254, 240,  24,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  25, 240, 254, 254, 153,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  64, 254, 254, 186,   7,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 166, 254, 254, 224,  12,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  14, 232, 254, 254, 254,  29,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  75, 254, 254, 254,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  18, 254, 254, 254, 254,  29,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  48, 254, 254, 254,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   2, 163, 254, 254, 254,  29,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  48, 254, 254, 254,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  94, 254, 254, 254, 200,  12,   0,   0,\n",
       "          0,   0,   0,   0,   0,  16, 209, 254, 254, 150,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  15, 206, 254, 254, 254, 202,  66,   0,\n",
       "          0,   0,   0,   0,  21, 161, 254, 254, 245,  31,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  60, 212, 254, 254, 254, 194,  48,\n",
       "         48,  34,  41,  48, 209, 254, 254, 254, 171,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  86, 243, 254, 254, 254, 254,\n",
       "        254, 233, 243, 254, 254, 254, 254, 254,  86,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 114, 254, 254, 254, 254,\n",
       "        254, 254, 254, 254, 254, 254, 239,  86,  11,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  13, 182, 254, 254, 254,\n",
       "        254, 254, 254, 254, 254, 243,  70,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,  76, 146, 254,\n",
       "        255, 254, 255, 146,  19,  15,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data.iloc[1, 1:]).reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e9fe3636a0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(data.iloc[int(np.random.random() * data.shape[0]), 1:]).reshape((28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data[:1000].T\n",
    "test_y = data_test[0]\n",
    "test_x = data_test[1:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[1000:].T\n",
    "train_y = data_train[0]\n",
    "train_x = data_train[1:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "\n",
    "        # self.weights = np.random.randn(n_inputs, n_neurons)\n",
    "        self.weights = np.random.random((n_inputs, n_neurons)) - 0.5\n",
    "\n",
    "        # self.biases = np.zeros(1, n_neurons)\n",
    "        self.biases = np.random.random((1, n_neurons)) - 0.5\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(inputs, self.weights)  + self.biases\n",
    "\n",
    "\n",
    "    def backpropagation(self, output_error, lr):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.inputs.T, output_error)\n",
    "\n",
    "        self.weights -= lr * weights_error\n",
    "        self.bias -= lr * output_error\n",
    "        return input_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activations:\n",
    "\n",
    "    def ReLU(self, inputs):\n",
    "        return np.maximum(0, inputs)\n",
    "\n",
    "    def ReLU_derivative(self, inputs):\n",
    "        return (inputs > 0) * 1\n",
    "            \n",
    "    def Sigmoid(self, inputs):\n",
    "        return (1 / 1 + np.exp(-inputs))\n",
    "        \n",
    "    def Sigmoid_derivative(self, inputs):\n",
    "        return (1 / 1 + np.exp(-inputs))*(1- (1 / 1 + np.exp(-inputs)))\n",
    "\n",
    "    def SoftMax(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis = 1, keepdims = True))\n",
    "        return exp_values/ np.sum(exp_values)\n",
    "\n",
    "    def SoftMax_derivative(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction:\n",
    "    def MSE(self, true_values, predicted_values):\n",
    "        return np.mean(np.square(true_values - predicted_values))\n",
    "    def sparse_categorical_crossentropy(self, true_values, predicted_values):\n",
    "        # The predicted values come from the softmax\n",
    "        return -np.sum(true_values + np.log(predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = Activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer_Dense(784, 10)\n",
    "layer2 = Layer_Dense(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 2)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:,0:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.forward(train_x[:,0:1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-596.96658497, -462.47427404,  689.48328394,  311.09110403,\n",
       "         156.43275582,  460.03742803, 1071.57903503,  112.95009842,\n",
       "         798.45417041,  556.58613587]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-596.96658497, -462.47427404,  689.48328394,  311.09110403,\n",
       "        156.43275582,  460.03742803, 1071.57903503,  112.95009842,\n",
       "        798.45417041,  556.58613587])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation1 = activation.SoftMax(layer1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2.forward(activation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  89.73320551, -395.01224706],\n",
       "       [-117.12179805, -244.45749081]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7],\n",
       "       [0.8],\n",
       "       [0.4]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([[0.1, 0.2, 0.7], [0.8, 0.1, 0.1], [0.3, 0.4, 0.3]])\n",
    "np.amax(y_pred, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coursera Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"Layer dims contains the dimension of each layer in the neural network\"\"\"\n",
    "    parameters = {}\n",
    "\n",
    "    num_layers = len(layer_dims) # as the input layer is taken as 0\n",
    "    for i in range(1, num_layers):\n",
    "        parameters[f\"W{i}\"] = np.random.random((layer_dims[i-1], layer_dims[i])) - 0.5\n",
    "        parameters[f\"b{i}\"] = np.random.random((1, layer_dims[i])) - 0.5\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.0488135 ,  0.21518937,  0.10276338,  0.04488318, -0.0763452 ,\n",
       "          0.14589411, -0.06241279,  0.391773  ,  0.46366276, -0.11655848],\n",
       "        [ 0.29172504,  0.02889492,  0.06804456,  0.42559664, -0.42896394,\n",
       "         -0.4128707 , -0.4797816 ,  0.33261985,  0.27815675,  0.37001215],\n",
       "        [ 0.47861834,  0.29915856, -0.03852064,  0.28052918, -0.38172557,\n",
       "          0.13992102, -0.35664671,  0.44466892,  0.02184832, -0.08533806]]),\n",
       " 'b1': array([[-0.23544439,  0.27423369, -0.04384967,  0.06843395, -0.4812102 ,\n",
       "          0.1176355 ,  0.11209572,  0.116934  ,  0.44374808,  0.1818203 ]]),\n",
       " 'W2': array([[-0.1404921 , -0.06296805,  0.1976312 , -0.43977453,  0.16676672],\n",
       "        [ 0.17063787, -0.28961744, -0.3710737 , -0.18457165, -0.13628923],\n",
       "        [ 0.07019677, -0.06139849,  0.48837384, -0.39795519, -0.29112324],\n",
       "        [-0.33869048,  0.15310833, -0.2467084 , -0.03368923, -0.25557441],\n",
       "        [-0.34103042, -0.38962486,  0.15632959, -0.36181705, -0.30341764],\n",
       "        [-0.13127483,  0.32099323, -0.40289872,  0.33794491, -0.40390159],\n",
       "        [ 0.47645947, -0.0313488 ,  0.47676109,  0.10484552,  0.23926358],\n",
       "        [-0.46081221, -0.21719304, -0.37980344, -0.2038598 , -0.38127228],\n",
       "        [-0.18201682, -0.08573701, -0.4358525 ,  0.19247212,  0.06660145],\n",
       "        [-0.23461051,  0.02324805, -0.40605949,  0.0759465 ,  0.4292962 ]]),\n",
       " 'b2': array([[-0.18143105,  0.16741038, -0.36820214,  0.2163272 , -0.21059391]])}"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters([3, 10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(A, weights, biases):\n",
    "    cache = A, weights, biases\n",
    "    return np.doT(weights, A) + biases, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    n = y_true.shape[0]\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "def mse_gradient(y_true, y_pred):\n",
    "    n = y_true.shape[0]\n",
    "    mse_grad = -2 * (y_true - y_pred) / n\n",
    "    return mse_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_categorical_crossentropy(y_true, logits):\n",
    "    # y_true is an integer array containing the true class indices (not one-hot encoded)\n",
    "    n = y_true.shape[0]\n",
    "    softmax_output = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n",
    "    # Clip softmax_output to avoid numerical instability (e.g., log(0) = -inf)\n",
    "    epsilon = 1e-15\n",
    "    softmax_output = np.clip(softmax_output, epsilon, 1 - epsilon)\n",
    "    crossentropy = -np.log(softmax_output[np.arange(n), y_true])\n",
    "    return crossentropy.mean()\n",
    "\n",
    "def sparse_categorical_crossentropy_gradient(y_true, logits):\n",
    "    n = y_true.shape[0]\n",
    "    softmax_output = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n",
    "    softmax_output[np.arange(n), y_true] -= 1\n",
    "    softmax_output /= n\n",
    "    return softmax_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(dz, cache):\n",
    "    A_prev, weights, baises = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m) * np.dot(dZ, A_prev.T)\n",
    "    db = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev, dW, db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
