{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./digit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        4\n",
       "4        0\n",
       "        ..\n",
       "41995    0\n",
       "41996    1\n",
       "41997    7\n",
       "41998    6\n",
       "41999    9\n",
       "Name: label, Length: 42000, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data[\"label\"], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9\n",
       "0      0  1  0  0  0  0  0  0  0  0\n",
       "1      1  0  0  0  0  0  0  0  0  0\n",
       "2      0  1  0  0  0  0  0  0  0  0\n",
       "3      0  0  0  0  1  0  0  0  0  0\n",
       "4      1  0  0  0  0  0  0  0  0  0\n",
       "...   .. .. .. .. .. .. .. .. .. ..\n",
       "41995  1  0  0  0  0  0  0  0  0  0\n",
       "41996  0  1  0  0  0  0  0  0  0  0\n",
       "41997  0  0  0  0  0  0  0  1  0  0\n",
       "41998  0  0  0  0  0  0  1  0  0  0\n",
       "41999  0  0  0  0  0  0  0  0  0  1\n",
       "\n",
       "[42000 rows x 10 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = pd.concat([data,df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = data_encoded.drop([\"label\"], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 794 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995       0       0       0       0       0       0       0       0       0   \n",
       "41996       0       0       0       0       0       0       0       0       0   \n",
       "41997       0       0       0       0       0       0       0       0       0   \n",
       "41998       0       0       0       0       0       0       0       0       0   \n",
       "41999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  0  1  2  3  4  5  6  7  8  9  \n",
       "0           0  ...  0  1  0  0  0  0  0  0  0  0  \n",
       "1           0  ...  1  0  0  0  0  0  0  0  0  0  \n",
       "2           0  ...  0  1  0  0  0  0  0  0  0  0  \n",
       "3           0  ...  0  0  0  0  1  0  0  0  0  0  \n",
       "4           0  ...  1  0  0  0  0  0  0  0  0  0  \n",
       "...       ...  ... .. .. .. .. .. .. .. .. .. ..  \n",
       "41995       0  ...  1  0  0  0  0  0  0  0  0  0  \n",
       "41996       0  ...  0  1  0  0  0  0  0  0  0  0  \n",
       "41997       0  ...  0  0  0  0  0  0  0  1  0  0  \n",
       "41998       0  ...  0  0  0  0  0  0  1  0  0  0  \n",
       "41999       0  ...  0  0  0  0  0  0  0  0  0  1  \n",
       "\n",
       "[42000 rows x 794 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "           ..\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Name: 1, Length: 784, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded.iloc[1, :784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18,  30, 137,\n",
       "        137, 192,  86,  72,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  13,  86, 250, 254, 254,\n",
       "        254, 254, 217, 246, 151,  32,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  16, 179, 254, 254, 254, 254,\n",
       "        254, 254, 254, 254, 254, 231,  54,  15,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  72, 254, 254, 254, 254, 254,\n",
       "        254, 254, 254, 254, 254, 254, 254, 104,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  61, 191, 254, 254, 254, 254, 254,\n",
       "        109,  83, 199, 254, 254, 254, 254, 243,  85,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 172, 254, 254, 254, 202, 147, 147,\n",
       "         45,   0,  11,  29, 200, 254, 254, 254, 171,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1, 174, 254, 254,  89,  67,   0,   0,\n",
       "          0,   0,   0,   0, 128, 252, 254, 254, 212,  76,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  47, 254, 254, 254,  29,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  83, 254, 254, 254, 153,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  80, 254, 254, 240,  24,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  25, 240, 254, 254, 153,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  64, 254, 254, 186,   7,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 166, 254, 254, 224,  12,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  14, 232, 254, 254, 254,  29,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  75, 254, 254, 254,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  18, 254, 254, 254, 254,  29,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  48, 254, 254, 254,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   2, 163, 254, 254, 254,  29,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  48, 254, 254, 254,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  94, 254, 254, 254, 200,  12,   0,   0,\n",
       "          0,   0,   0,   0,   0,  16, 209, 254, 254, 150,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  15, 206, 254, 254, 254, 202,  66,   0,\n",
       "          0,   0,   0,   0,  21, 161, 254, 254, 245,  31,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  60, 212, 254, 254, 254, 194,  48,\n",
       "         48,  34,  41,  48, 209, 254, 254, 254, 171,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  86, 243, 254, 254, 254, 254,\n",
       "        254, 233, 243, 254, 254, 254, 254, 254,  86,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 114, 254, 254, 254, 254,\n",
       "        254, 254, 254, 254, 254, 254, 239,  86,  11,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  13, 182, 254, 254, 254,\n",
       "        254, 254, 254, 254, 254, 243,  70,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,  76, 146, 254,\n",
       "        255, 254, 255, 146,  19,  15,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_encoded.iloc[1, :784]).reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c1cb1a0460>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(data.iloc[int(np.random.random() * data.shape[0]), 1:]).reshape((28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = np.array(data_encoded)\n",
    "m, n = data_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 794)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_encoded[:1000]\n",
    "test_y = data_test[:, 784:]\n",
    "test_x = data_test[:,:784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_encoded[1000:] #.T\n",
    "train_y = data_train[:, 784:]\n",
    "train_x = data_train[:,:784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ReLU(inputs):\n",
    "    return np.maximum(0, inputs)\n",
    "\n",
    "def ReLU_derivative(inputs):\n",
    "    return (inputs > 0) * 1\n",
    "        \n",
    "def Sigmoid(inputs):\n",
    "    return (1 / 1 + np.exp(-inputs))\n",
    "    \n",
    "def Sigmoid_derivative(inputs):\n",
    "    return (1 / 1 + np.exp(-inputs))*(1- (1 / 1 + np.exp(-inputs)))\n",
    "\n",
    "def SoftMax(inputs):\n",
    "    exp_values = np.exp(inputs - np.max(inputs, axis = 1, keepdims = True))\n",
    "    return exp_values/ np.sum(exp_values)\n",
    "\n",
    "\n",
    "def SoftMax_derivative(inputs):\n",
    "    exp_shifted = np.exp(x - x.max())\n",
    "    return exp_shifted / np.sum(exp_shifted, axis = 0) * (1 - exp_shifted / np.sum(exp_shifted, axis = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coursera Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"Layer dims contains the dimension of each layer in the neural network\"\"\"\n",
    "    parameters = {}\n",
    "\n",
    "    num_layers = len(layer_dims) # as the input layer is taken as 0\n",
    "    for i in range(1, num_layers):\n",
    "        parameters[f\"w{i}\"] = (np.random.random((layer_dims[i-1], layer_dims[i])) - 0.5).T\n",
    "        parameters[f\"b{i}\"] = (np.random.random((1, layer_dims[i])) - 0.5).T\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [train_x[0].shape[0], 10,train_y[0].shape[0]]\n",
    "parameters = initialize_parameters(layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[\"w1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[\"b1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, parameters):\n",
    "    \n",
    "    w1 = parameters[\"w1\"] # (10, 784)\n",
    "    w2 = parameters[\"w2\"] # (10, 10)\n",
    "    b1 = parameters[\"b1\"] # (10, 1)\n",
    "    b2 = parameters[\"b2\"] # (10, 1)\n",
    "    \n",
    "    Z1 = np.matmul(w1, X).reshape(-1,1)\n",
    "\n",
    "    \n",
    "    Z1 += b1\n",
    "    A1 = ReLU(Z1)    \n",
    "    \n",
    "    Z2 = np.matmul(w2, A1).reshape(-1,1)\n",
    "    Z2 += b2\n",
    "    \n",
    "\n",
    "    \n",
    "    A2 = Softmax(Z2)\n",
    "    \n",
    "    cache = {\n",
    "        \"Z1\": Z1,\n",
    "        \"A1\": A1,\n",
    "        \"Z2\": Z2, \n",
    "        \"A2\": A2\n",
    "    }\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(X, y, parameters, cache, alpha=0.01):\n",
    "    \n",
    "    m = y.shape[1]\n",
    "    Z1, A1, Z2, A2 = cache\n",
    "    W1, _, W2, _ = parameters\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2, A1.T) / m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * (Z1 > 0)\n",
    "    dW1 = np.dot(dZ1, X.T) / m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "\n",
    "    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, learning_rate):\n",
    "    w1, b1, w2, b2 = parameters\n",
    "    dW1, db1, dW2, db2 = gradients\n",
    "\n",
    "    w1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    w2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "    return {\"W1\": w1, \"b1\": b1, \"W2\": w2, \"b2\": b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(Y_pred, Y_true):\n",
    "    m = Y_true.shape[1]\n",
    "    loss = -np.sum(Y_true * np.log(Y_pred + 1e-8)) / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=0, keepdims=True)) # For numerical stability\n",
    "    return exp_z / np.sum(exp_z, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, hidden_size, output_size, learning_rate, epochs):\n",
    "    input_size = X.shape[0]\n",
    "    parameters = initialize_parameters(input_size, hidden_size, output_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        cache = forward_pass(X, parameters)\n",
    "        loss = cross_entropy_loss(cache[3], Y)\n",
    "        gradients = backward_pass(X, Y, parameters, cache)\n",
    "        parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_parameters = train(X, Y, hidden_size, output_size, learning_rate, epochs)\n",
    "predictions = predict(X, trained_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_cross_entropy(y_true, y_pred):\n",
    "    loss = 0\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        loss = loss + (-true) * np.log(pred)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### training ####################\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41000 [00:00<?, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23812\\3784884760.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  return (1 / 1 + np.exp(-inputs))\n",
      "  0%|          | 0/41000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10,64) and (784,) not aligned: 64 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Python\\DataMining\\NeuralNetwork\\neural.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m hit_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(samples)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     m_state \u001b[39m=\u001b[39m backward_pass(train_x[i], train_y[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# add partial cost\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     cost \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m categorical_cross_entropy(m_state[\u001b[39m'\u001b[39m\u001b[39mo3\u001b[39m\u001b[39m'\u001b[39m], y_train[i])\n",
      "\u001b[1;32md:\\Python\\DataMining\\NeuralNetwork\\neural.ipynb Cell 35\u001b[0m in \u001b[0;36mbackward_pass\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_pass\u001b[39m(x, y):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# do the forward pass, register the state of the network\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     nn_state \u001b[39m=\u001b[39m forward_pass(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# small deltas: derivatives of the error w.r.t. z\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     nn_state[\u001b[39m'\u001b[39m\u001b[39md3\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nn_state[\u001b[39m'\u001b[39m\u001b[39mo3\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m y\n",
      "\u001b[1;32md:\\Python\\DataMining\\NeuralNetwork\\neural.ipynb Cell 35\u001b[0m in \u001b[0;36mforward_pass\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m nn_state[\u001b[39m'\u001b[39m\u001b[39mo2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m Sigmoid(nn_state[\u001b[39m'\u001b[39m\u001b[39mz2\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# from hidden 2 to output\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m nn_state[\u001b[39m'\u001b[39m\u001b[39mz3\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(model[\u001b[39m'\u001b[39;49m\u001b[39mw2\u001b[39;49m\u001b[39m'\u001b[39;49m], nn_state[\u001b[39m'\u001b[39;49m\u001b[39mo2\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m nn_state[\u001b[39m'\u001b[39m\u001b[39mo3\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m SoftMax(nn_state[\u001b[39m'\u001b[39m\u001b[39mz3\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Python/DataMining/NeuralNetwork/neural.ipynb#Y104sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m nn_state\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10,64) and (784,) not aligned: 64 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "t_rate = 0.001\n",
    "# train\n",
    "print('################### training ####################')\n",
    "for e in range(epochs):\n",
    "    print('epoch:', e)\n",
    "    \n",
    "    samples = train_x.shape[0]\n",
    "    cost = 0\n",
    "    hit_count = 0\n",
    "    for i in tqdm(range(samples)):\n",
    "        m_state = backward_pass(train_x[i], train_y[i])\n",
    "        # add partial cost\n",
    "        cost += categorical_cross_entropy(m_state['o3'], y_train[i])\n",
    "        \n",
    "        # stochastic gradient descent\n",
    "        # update weights\n",
    "        model['w0'] -= t_rate * m_state['D0']\n",
    "        model['w1'] -= t_rate * m_state['D1']\n",
    "        model['w2'] -= t_rate * m_state['D2']\n",
    "        \n",
    "        if np.argmax(m_state['o3']) == np.argmax(y_train[i]):\n",
    "            # successful detection\n",
    "            hit_count += 1\n",
    "# performance evaluation\n",
    "    cost = cost / samples\n",
    "    accuracy = hit_count / samples\n",
    "    print('cost:', cost, 'accuracy:', accuracy)\n",
    "# save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aayush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    w_1 = np.random.random((100, 28*28)) * 0.01 - 0.005\n",
    "    b_1 = (np.random.random((100,)) * 0.01 - 0.005).reshape(-1,1)\n",
    "    w_2 = np.random.random((10, 100)) * 0.01 - 0.005\n",
    "    b_2 = (np.random.random((10,)) * 0.01 - 0.005).reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    params = {\n",
    "        \"w_1\": w_1,\n",
    "        \"w_2\": w_2,\n",
    "        \"b_1\": b_1,\n",
    "        \"b_2\": b_2\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def ReLU(X):\n",
    "    # shape = X.shape\n",
    "    # temp = X.reshape(-1,1)\n",
    "    # for i in range(len(temp)):\n",
    "    #     temp[i] = max(0, temp[i])\n",
    "        \n",
    "    # temp = temp.reshape(shape)\n",
    "    # return temp\n",
    "    return np.maximum(X, np.zeros(X.shape))\n",
    "\n",
    "def d_ReLU(X):\n",
    "    return X >= 0\n",
    "\n",
    "def Softmax(x):\n",
    "    # x = x / 100\n",
    "    x = np.float128(x)\n",
    "    # print(np.exp(x) / np.exp(x).sum())\n",
    "    return np.exp(x) / np.exp(x).sum()\n",
    "\n",
    "def categorical_cross_entropy(y_true, y_pred):\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        loss = loss + (-true) * np.log(pred)\n",
    "        \n",
    "    return loss\n",
    "    \n",
    "\n",
    "def forward(X, params):\n",
    "    \n",
    "    # X.shape = (784,1)\n",
    "    w_1 = params[\"w_1\"] # (10, 784)\n",
    "    w_2 = params[\"w_2\"] # (10, 10)\n",
    "    b_1 = params[\"b_1\"] # (10, 1)\n",
    "    b_2 = params[\"b_2\"] # (10, 1)\n",
    "    \n",
    "    z_1 = np.matmul(w_1, X).reshape(-1,1)\n",
    "    # print(z_1.shape, b_1.shape)\n",
    "    \n",
    "    z_1 += b_1\n",
    "    a_1 = ReLU(z_1)    \n",
    "    \n",
    "    z_2 = np.matmul(w_2, a_1).reshape(-1,1)\n",
    "    z_2 += b_2\n",
    "    \n",
    "    # print(z_2.shape)\n",
    "    # z_2 = np.sqrt(np.abs(z_2))\n",
    "    \n",
    "    \n",
    "    out = Softmax(z_2)\n",
    "    \n",
    "    cache = {\n",
    "        \"z_1\": z_1,\n",
    "        \"a_1\": a_1,\n",
    "        \"z_2\": z_2, \n",
    "        \"a_2\": out\n",
    "    }\n",
    "    return out, cache\n",
    "\n",
    "\n",
    "\n",
    "def backprop(X, y, params, cache, lr=0.01):\n",
    "    \n",
    "    # X: (784,) y: (10, 1)\n",
    "    \n",
    "    m = 1\n",
    "\n",
    "    z_1, a_1, z_2, a_2 = cache[\"z_1\"].reshape(-1, 1), cache[\"a_1\"].reshape(-1, 1), cache[\"z_2\"].reshape(-1, 1), cache[\"a_2\"].reshape(-1, 1)  # (10,)\n",
    "    \n",
    "    \n",
    "    w_1 = params[\"w_1\"] # (10, 784)\n",
    "    w_2 = params[\"w_2\"] # (10,10)\n",
    "    b_1 = params[\"b_1\"].reshape(-1, 1) # (10,1)\n",
    "    b_2 = params[\"b_2\"].reshape(-1, 1) # (10,1)\n",
    "    \n",
    "    # print(f\"X: {X.shape}\\ny: {y.shape}\\nw_1: {w_1.shape}\\nb_1: {b_1.shape}\\nw_2: {w_2.shape}\\nb_2: {b_2.shape}\\nz_1: {z_1.shape}\\na_1: {a_1.shape}\\nz_2: {z_2.shape}\\na_2: {a_2.shape}\")\n",
    "    \n",
    "    dz_2 = a_2 - y # (10,)\n",
    "    # print(f\"dz_2: {dz_2.shape}\")\n",
    "    dw_2 = np.matmul(dz_2, a_1.T) / m # (10,) * (1,10) = (10,10)\n",
    "    # print(f\"dw_2: {dw_2.shape}\")\n",
    "    db_2 = np.sum(dz_2, axis=1, keepdims=True) / m # ()\n",
    "    # print(f\"db_2: {db_2.shape}\")\n",
    "    \n",
    "    dz_1 = np.multiply(np.matmul(w_2.T, dz_2), d_ReLU(z_1))\n",
    "    # print(f\"dz_1: {dz_1.shape}\")\n",
    "    db_1 = np.sum(dz_1, axis=1, keepdims=True) / m\n",
    "    # print(f\"db_1: {db_1.shape}\")\n",
    "    dw_1 = np.matmul(dz_1, X.T) / m\n",
    "    # print(f\"dw_1: {dw_1.shape}\")\n",
    "    \n",
    "    w_1 = w_1 - lr * dw_1\n",
    "    w_2 = w_2 - lr * dw_2\n",
    "    b_1 = b_1 - lr * db_1\n",
    "    b_2 = b_2 - lr * db_2\n",
    "    \n",
    "    params = {\n",
    "        \"w_1\": w_1,\n",
    "        \"w_2\": w_2,\n",
    "        \"b_1\": b_1,\n",
    "        \"b_2\": b_2\n",
    "    }\n",
    "    \n",
    "    # print(f\"w_1: {w_1.shape}\\nb_1: {b_1.shape}\\nw_2: {w_2.shape}\\nb_2: {b_2.shape}\")\n",
    "    \n",
    "    \n",
    "    return params\n",
    "    \n",
    "def fit(X, y, iter=30, lr=0.01):\n",
    "    params = initialize_parameters()\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    for i in range(iter):\n",
    "        loss = 0\n",
    "        for i in tqdm(range(m)):\n",
    "            # print(X[:, i].shape, y[:, i])\n",
    "            out, cache = forward(X[:, i], params)\n",
    "            \n",
    "            params = backprop(X[:, i].reshape(-1, 1), y[:, i].reshape(-1,1), params, cache, lr=lr)\n",
    "            \n",
    "            # print(y[:,i].shape, out.shape)\n",
    "            \n",
    "            loss += categorical_cross_entropy(y[:, i], out)\n",
    "        \n",
    "        print(\"loss: \", loss/m)\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to initialize the parameters of the neural network\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    # Initialize the weights and biases for the first hidden layer\n",
    "    W1 = np.random.randn(hidden_size, input_size) * 0.01\n",
    "    b1 = np.zeros((hidden_size, 1))\n",
    "    # Initialize the weights and biases for the output layer\n",
    "    W2 = np.random.randn(output_size, hidden_size) * 0.01\n",
    "    b2 = np.zeros((output_size, 1))\n",
    "    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "\n",
    "# ReLU activation function\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "# Softmax activation function for the output layer\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=0, keepdims=True)) # For numerical stability\n",
    "    return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n",
    "\n",
    "# Function for the forward pass of the neural network\n",
    "def forward_pass(X, parameters):\n",
    "    W1, b1, W2, b2 = parameters\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# Function to predict the output labels for given input features\n",
    "def predict(X, parameters):\n",
    "    _, _, _, A2 = forward_pass(X, parameters)\n",
    "    return np.argmax(A2, axis=0)\n",
    "\n",
    "# Cross-entropy loss function\n",
    "def cross_entropy_loss(Y_pred, Y_true):\n",
    "    m = Y_true.shape[1]\n",
    "    loss = -np.sum(Y_true * np.log(Y_pred + 1e-8)) / m\n",
    "    return loss\n",
    "\n",
    "# Function for the backward pass to compute gradients\n",
    "def backward_pass(X, Y, parameters, cache):\n",
    "    m = Y.shape[1]\n",
    "    Z1, A1, Z2, A2 = cache\n",
    "    W1, _, W2, _ = parameters\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2, A1.T) / m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * (Z1 > 0)  # Derivative of ReLU\n",
    "    dW1 = np.dot(dZ1, X.T) / m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "\n",
    "    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return gradients\n",
    "\n",
    "# Function to update the parameters using gradient descent\n",
    "def update_parameters(parameters, gradients, learning_rate):\n",
    "    W1, b1, W2, b2 = parameters\n",
    "    dW1, db1, dW2, db2 = gradients\n",
    "\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "\n",
    "# Function to train the neural network\n",
    "def train(X, Y, hidden_size, output_size, learning_rate, epochs):\n",
    "    input_size = X.shape[0]\n",
    "    parameters = initialize_parameters(input_size, hidden_size, output_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        cache = forward_pass(X, parameters)\n",
    "        loss = cross_entropy_loss(cache[3], Y)\n",
    "        gradients = backward_pass(X, Y, parameters, cache)\n",
    "        parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return parameters\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X and Y are your input features and labels as numpy arrays.\n",
    "# X: input features with shape (input_size, num_samples)\n",
    "# Y: one-hot encoded labels with shape (output_size, num_samples)\n",
    "\n",
    "input_size = X.shape[0]\n",
    "output_size = Y.shape[0]\n",
    "hidden_size = 64\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "trained_parameters = train(X, Y, hidden_size, output_size, learning_rate, epochs)\n",
    "predictions = predict(X, trained_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
